%\documentclass[mathserif,aspectratio=1610]{beamer}
\documentclass[mathserif,handout,aspectratio=1610]{beamer}
%\usepackage{beamerthemeshadow}

\input{$HOME/tex/inputs/defsSkript}%$
\input{$HOME/tex/inputs/styleBeamerVkoekMa}%$
%\input{styleBeamerVkoekMa}%$

\usepackage{graphicx}

%\newcommand{\pathDiscrChoice}{$HOME/vorlesungen/Verkehrsoekonometrie_Ma/discrChoice_cc_Levmar} %$
\newcommand{\pathDiscrChoice}{figsDiscr} 

%##############################################################

\begin{document}

\section{11 \  Advanced Concepts of Discrete-Choice Theory}

%###################################################
\frame{  %title layout
%###################################################
\makePale{1.00}{0.50}{0.70}{1.40}{1.40}

\placebox{0.50}{0.42}{
  \figSimple{1.60\textwidth}
    {figsDiscr/nonlinUtility_4param_lnL_beta2_beta3_eng.png}}
%makePale{opacity}{centerXrel}{centerYrel}{wrel}\{hrel} 
\makePale{0.70}{0.50}{0.70}{1.40}{1.40}

\placebox{0.75}{0.81}{\parbox{0.45\textwidth}{\myheading{
11 \ Advanced Concepts of\\ \hspace*{1em} Discrete-Choice Theory
}}}

\placebox{0.40}{0.30}{\parbox{0.8\textwidth}{
{\large
\bi
\item 11.1 Parameter Nonlinear Models
\item 11.2 GEV and Nested Logit Models
\bi
\item 11.2.1 General Specification
\item 11.2.2 Nested Logit Model
\item 11.2.3 Example: Combined Destination and Mode Choice
\ei
\item 11.3 [Advanced I: Mixed-Logit Models (German script)]
\item 11.4 [Advanced II: How to Assess Reliability (German script)]
\ei
}
}}

}





\subsection{11.1 Parameter Nonlinear Models}

%##############################################################
\frame{\frametitle{11.1  \EinsteinPdflatex Parameter Nonlinear Models}
%##############################################################

Application: Determining subjective thresholds/indifference regions
\vspace{1em}

\begin{center}
\begin{tabular}{|c||c|c|c|c|} \hline
\myBox{3em}{Person\\class}
 & \myBox{5em}{Time\\Alternative~1 \\ \text{[min]}}
 & \myBox{5em}{Time\\Alternative~2\\ \text{[min]}}
 & \myBox{2em}{Choice\\Alt.~1}
 & \myBox{2em}{Choice\\Alt.~2} \\ \hline
1 & 25 & 30 & 11 & 10 \\
2 & 30 & 30 & 10 & 10 \\
3 & 35 & 30 & 10 & 10 \\
4 & 40 & 30 & 9 & 11 \\
5 & 45 & 30 & 5 & 15 \\
6 & 50 & 30 & 2 & 15 \\
7 & 55 & 30 & 1 & 15 \\
8 & 60 & 30 & 0 & 15 \\ \hline
\end{tabular}
\end{center}
}

%##############################################################
\frame{\frametitle{Modelling the threshold}
%##############################################################

\placebox{0.5}{0.62}{\figSimple{1.0\textwidth}
  {figsDiscr/nonlinUtility_4param_skriptFig_eng.png}}

\placebox{0.26}{0.16}{\parbox{0.5\textwidth}{
{\small
\bdm
V_{n1}-V_{n2}=\beta_1 +\beta_2\left[\Delta T_n+\beta_3 \,
  \tanh\left(\frac{\Delta T_n}{\beta_4}\right)\right]
\edm
\vspace{-2em}
\begin{align*}
\visible<2->{\hatbeta_1 &= 0.043 \pm 0.236 \ \text{\red{AC}}\\[-0.8ex]}
\visible<3->{\hatbeta_2 &= -0.29 \pm 0.38 
   \ \text{\red{asymptotic time sensitivity}}\\[-0.8ex]}
\visible<4->{\hatbeta_3 &= -15 \pm 18
   \ \text{\red{degree of nonlinearity $ \ge -\beta_4$}}\\[-0.8ex]}
\visible<5->{\hatbeta_4 &= 14 \pm 21
   \ \text{\red{threshold width}} }
\end{align*}
}}}

\visible<6->{\placebox{0.74}{0.15}{\parbox{0.4\textwidth}{
\red{\textbf{!!}} Generally, $L(\vecbeta)$ has no longer a unique maximum,
here, because of
\bdm
\beta_3 \,\tanh\left(\frac{\Delta T_n}{\beta_4}\right)
=
-\beta_3 \,\tanh\left(\frac{\Delta T_n}{-\beta_4}\right)
\edm
}}}


}


%##############################################################
\frame{\frametitle{The reverse: Increased
    sensitivity at reference point}
%##############################################################


\begin{center}
\begin{tabular}{|c||c|c|c|c|} \hline
\myBox{3em}{Person\\class}
 & \myBox{5em}{Time\\Alternative~1 \\ \text{[min]}}
 & \myBox{5em}{Time\\Alternative~2\\ \text{[min]}}
 & \myBox{2em}{Choice\\Alt.~1}
 & \myBox{2em}{Choice\\Alt.~2} \\ \hline
1 & 25 & 30 & 16 & 7 \\
2 & 30 & 30 & 10 & 10 \\
3 & 35 & 30 & 7 & 20 \\
4 & 40 & 30 & 3 & 20 \\
5 & 45 & 30 & 3 & 25 \\
6 & 50 & 30 & 2 & 30 \\
7 & 55 & 30 & 1 & 17 \\
8 & 60 & 30 & 2 & 50 \\ \hline
\end{tabular}
\end{center}

\vspace{1em}

Such increased sensitivity at the reference (here: equal trip times)
is proposed 
by the \bfdef{Prospect Theory} of Kahneman/Twersky in certain situations
}

%##############################################################
\frame{
%##############################################################

\placebox{0.5}{0.62}{\figSimple{1.0\textwidth}
  {figsDiscr/nonlinUtility_4param_Tversky_skriptFig_eng.jpg}}


\placebox{0.50}{0.16}{\parbox{0.5\textwidth}{
{\small
\bdm
V_{n1}-V_{n2}=\beta_1 +\beta_2\left[\Delta T_n+\beta_3 \,
  \tanh\left(\frac{\Delta T_n}{\beta_4}\right)\right]
\edm
\vspace{-2em}
\begin{align*}
\hatbeta_1 &= -0.08 \pm 0.25, \\[-0.8ex]
\hatbeta_2 &= -0.05 \pm 0.10,\\[-0.8ex]
\hatbeta_3 &= 27 \pm 101, \\[-0.8ex]
\hatbeta_4 &= 10 \pm 16
\end{align*}
}}}

\placebox{0.50}{0.90}{\parbox{0.65\textwidth}{
 \myheading{Modelling the increased sensitivity}} 
} 

}

%##############################################################
\frame{\frametitle{
Four further models applied to the threshold data}
%##############################################################

\fig{0.88\textwidth}{figsDiscr/nonlinUtility_3param2param.png}

}

\subsection{11.2 GEV and Nested Logit Models}

%##############################################################
\frame{\frametitle{11.2 GEV and Nested Logit Models}
%##############################################################
\textbf{Motivation}

When taking decisions, the available options are often coupled in a
way that i.i.d. random utilities are not applicable:
\bi
\item Destination and mode choice
\pause \item Destination city and job offers when about to moving
\pause \item Expansion of a company: Creating a new branch office and if so,
  where?
\ei
\pause In these cases, a decision involves taking two or more sub-decisions
with nearly fixed random utilities in the associated alternative sets,
so the total random utility is correlated

\vspace{1em}

$\Rightarrow$ \textbf{\red{Red-Bus}-\blue{Blue-Bus} problem.}

\pause \vspace{1em}

$\Rightarrow$ How to model this while retaining explicit expressions
for the choice probabilities?
}


%##############################################################
\frame{\frametitle{The \red{Red-Bus}-\blue{Blue-Bus} Problem}
%##############################################################
\visible<1>{\placebox{0.52}{0.45}{\figSimple{0.8\textwidth}
  {figsDiscr/redBus_only.png}}}

\visible<2->{\placebox{0.52}{0.45}{\figSimple{0.8\textwidth}
  {figsDiscr/redBus_only_perc.png}}}

\placebox{0.30}{0.20}{\parbox{0.3\textwidth}
  {Times and costs equal,\\
  AC zero}}

}

%##############################################################
\frame{\frametitle{The \red{Red-Bus}-\blue{Blue-Bus} Problem}
%##############################################################

\visible<1>{\placebox{0.52}{0.45}{\figSimple{0.8\textwidth}
 {figsDiscr/redBus_blueBus.png}}}

\visible<2->{\placebox{0.52}{0.45}{\figSimple{0.8\textwidth}
 {figsDiscr/redBus_blueBus_perc.png}}}


\placebox{0.30}{0.20}{\parbox{0.3\textwidth}
  {Times and costs equal,\\
  AC zero}}

\visible<2>{\placebox{0.45}{0.10}{\bfred{Not plausible!}}}

}


%##############################################################
\frame{\frametitle{Problem solved: 100\% correlated random utilities}
%##############################################################

\placebox{0.52}{0.45}{\figSimple{0.9\textwidth}
  {figsDiscr/redBus_blueBus_resolved_perc.png}}

\placebox{0.18}{0.25}{\parbox{0.3\textwidth}
  {Car and public transport\\
  have equal times and costs,\\
  AC zero}}

}

%##############################################################
\frame{\frametitle{Nontrivial nested decision: partial correlations}
%##############################################################

\visible<1>{\placebox{0.52}{0.45}{\figSimple{0.9\textwidth}
  {figsDiscr/redBus_blueBus_nontrivial.png}}}

\visible<2->{\placebox{0.52}{0.45}{\figSimple{0.9\textwidth}
  {figsDiscr/redBus_blueBus_nontrivial_perc.png}}}

\placebox{0.18}{0.25}{\parbox{0.3\textwidth}
  {All three modes \\
  have equal times and costs,\\
  AC zero}}

\visible<2->{\placebox{0.50}{0.08}{\parbox{\textwidth}
 {\bfred{Average PT utiliy higher than
that of bus or tram alone\\because some prefer tram, some bus}}}}

}


%##############################################################
\frame{\frametitle{The general GEV generating function}
%##############################################################

All the GEV models are defined via a \bfdef{Generating function
  $G(\vec{y})=G(y_1, ..., y_I)$} satisfying following formal
conditions:
\bi
\item Not negative: \quad $G(\vec{y}) \ge 0 \ \text{for all} \ \vec{y},$

\pause \item Asymptotics:\quad
     $ G \to \infty \ \text{if any} \ y_i \to \infty,$

\pause \item Sign of derivatives: \parbox{0.5\textwidth}{
\bdma
  G_i & \equiv & \ablpart{G}{y_i} \ge 0, \\
  G_{ij} & \equiv &  \ablpartmix{G}{y_i}{y_j} \le 0 \ \text{if $i\neq j$},\\
  G_{ijk} & \ge & 0 \ \text{and so on},
\edma
}

\pause \item Homogeneity of degree 1:
     $ G(\alpha \vec{y})=\alpha G(\vec{y})$
\ei
}

%##############################################################
\frame{\frametitle{The Nobel-Price winning result of McFadden et. al.}
%##############################################################

Any GEV function  $G(\vec{y})$ satisfying the above four conditions
\vspace{1em}

\bi
\item generates a random vector  $\veceps$ satisfying a generalized
  extreme-value distribution with the distribution function
\maindm{F(\vec{e})=P(\epsilon_1\le e_1, ..., \epsilon_I \le e_I)
  =e^{-G(\vec{y})} \ \text{with} \ y_i=e^{-e_i}} 
 \vspace{1em}

\pause \item has analytic choice probabilities when maximizing the total utilities $U_i=V_i+\epsilon_i$:
\maindm{
  P_i=\frac{y_iG_i(\vec{y})}{G(\vec{y})} \ \text{with} \ 
  G_i=\ablpart{G}{y_i}, \ y_i=e^{+V_i}}
\ei
\vspace{2em}

\bfAsk{?} Check why the above conditions for $G(\vec{y})$ must be true

}


%##############################################################
\frame{\frametitle{Question: Check the conditions for $G(\vec{y})$}
%##############################################################

\bi
\itemAsk \colAsk{Why $G(\vec{y}) \ge 0 \ \text{for all} \ \vec{y}$?}

\pause \itemAnswer \colAnswer{Because a distribution function $F=e^{-G}$
  must be $\le 1$ (the condition $F\ge 0$ is satisfied automatically)}

\pause \itemAsk \colAsk{Why $G \to \infty \ \text{if any} \ y_i \to \infty$?}

\pause \itemAnswer \colAnswer{If $y_i \to \infty$ then the argument 
$e_i=-\ln y_i$ of the distribution function tends to $-\infty$. Since
  the corresponding random variable $\epsilon_i$ is always $>-\infty$,
  we have $F=e^{-G}=0$, hence $G \to \infty$}

\pause \itemAsk \colAsk{Sign of derivatives of $G$?}

\pause \itemAnswer \colAnswer{We check only the first derivative
  $G_i=\ablpart{G}{y_i}$. We have $P_i=y_iG_i/G$ with $P_i$,
  $y_i=e^{-e_i}$ and $G$ because of the first requirement all
  $\ge 0$. Hence $G_i\ge 0$. The other conditions follow from the
  non-negativity of the distribution functions}
\pause \itemAsk \colAsk{Homogeneity $ G(\alpha \vec{y})=\alpha G(\vec{y})$
  for any $\alpha>0$?}
\pause \itemAnswer \colAnswer{Because of $P_i=y_iG_i/G$ and the scaling
  invariance $P(\epsilon_1<e_1)=P(\lambda \epsilon_1<\lambda e_1)$
  with $\alpha=e^{\lambda}$}
\ei
}


%##############################################################
\frame{\frametitle{Special Case I: Multinomial-Logit}
%##############################################################

\bi
\item Generating function: 
\bdm
G(\vec{y})\sup{MNL}=\sum_{j=1}^{I} y_j
\edm

\pause \item Distribution function of the random utilities (RUs):
\bdma
F(\vec{e}) &=& \exp\left[-G\left(e^{-e_1}, ...\right)\right]
 = \exp\bigg(-\sum_j e^{-e_j}\bigg)\\
 &=& \prod_j \exp \left(-e^{-e_j}\right)
\ \Rightarrow \ \epsilon_i \sim \ \text{i.i.d. Gumbel}
\edma

\pause \item Choice probabilities:
\bdma
G_i &=& \ablpart{G}{y_i} =1, \\
P_i &=& \frac{y_i}{\sum_{j=1}^{I} y_j}=\frac{\exp(V_i)}{\sum_{j=1}^{I} \exp(V_j)}
\edma
\ei

}


%##############################################################
\frame{\frametitle{Special Case II: Two-level Nested Logit model}
%##############################################################
{\small\bi
\item Hierarchical decision: $i=(l,m)$, $l$: top-level alternatives,
  $m$ second-level alternatives depending on $l$
\vspace{0.5em}

\pause \item Generating GEV function: 
\bdm
G\sup{NL}(\vec{y})=\sum_{l=1}^L 
 \bigg(\sum_{m=1}^{M_l} y_{lm}^{1/\lambda_l}\bigg)^{\lambda_l}
\edm

where $\lambda_l \in [0,1]$ determine the correlations of the RUs in
``nest'' $l$:% with $M_l$ dependent alternatives:
\bi
\item $\lambda_l \to 1$: Limit of MNL, zero correlation \colAsk{$\Rightarrow$
  check it!}
\item  $\lambda_l \to 0$: no RUs inside the nests, correlation=1:
  \bfdef{sequential model: blue and red buses}
\ei
\vspace{0.5em}

\pause \item Distribution of the RUs:
\ei
\vspace{-2em}

\pause 
\bdma
F(\vec{e}) &=&\exp\bigg[-\sum_l \left(
  \sum_m e^{-e_{lm}/\lambda_l}\right)^{\lambda_l}\bigg]
 = \prod_l \exp\bigg[-\left(
  \sum_m e^{-e_{lm}/\lambda_l}\right)^{\lambda_l}\bigg]\\
 &=& \prod_l F_l(\vec{e}_l) 
\red{\Rightarrow \text{independent at top level}}
\edma
}

}

%##############################################################
\frame{\frametitle{Nested Logit choice probabilities}
%##############################################################

Insert $G\sup{NL}(\vec{y})$ into the general expression $P_i=y_iG_i/G$:
\bdm
P_i=P_{lm}=P_l P_{m|l}
 =\frac{e^{V_{lm}/\lambda_l}\left(\sum_{m'}e^{V_{lm'}/\lambda_l}\right)^{\lambda_l-1}}
  {\sum_{l'} \left(\sum_{m'}
    e^{V_{l'm'}/\lambda_{l'}}\right)^{\lambda_{l'}}}
\edm

%\pause
%{\small
%\bi
%\itemAsk Show that, if all $\lambda_l=1$, the normal MNL choice
%probabilities are obtained, i.e.,  all combinations $lm$ are independent
%\pause \itemAsk Show that, in the limit of all  $\lambda_l \to 0$, the choice
%probabilities are
%\bdm
%P_{lm}=\frac{\exp(V_{lm^*_l})}{\sum_l' \exp(V_{l'm^*_{l'}})}
%\edm
%if, for a given nest $l$, the alternative $m=m^*_l$ has the maximum
%utility $V$ of this nest, and $P_{lm}=0$, otherwise.
%\pause \itemAsk Diskuss why, in the case $\lambda_l \to 0$, the inner choice
%is deterministic, and each nest is a given single alternative
%subjected to a normal MNL: \bfdef{sequential model}
%\ei
%}

}

%##############################################################
\frame{\frametitle{A more intuitive form of the NL choice probabilities}
%##############################################################

\bi
\item Set/assume
\maindmIntext{
V_{lm}=W_l+\tilde{V}_{lm}
}
\bi
\item $W_l$: top-level contributions not appearing inside the nests
\item $\tilde{V}_{lm}$: inner
  contributions of alternative $m$ in nest $l$
\ei

\pause \item Then, the NL choice probabilities can be formulated as
\maindm{
P_{lm}=P_l P_{m|l}, \quad
P_l=\frac{e^{W_l+\lambda_l I_l}} 
 {\sum_{l'}e^{W_{l'}+\lambda_{l'} I_{l'}}}, \quad
P_{m|l}= \frac{e^{\tilde{V}_{lm}/\lambda_l}}{\sum_{m'}e^{\tilde{V}_{lm'}/\lambda_l}}
}
with the \bfdef{inclusion values}
\maindmIntext{
  I_l=\ln\left(\sum_{m}e^{\tilde{V}_{lm}/\lambda_l}\right)
}
\ei

{\small
\bi
\pause \itemAsk Argue that the outer nest decision is a normal MNL with the
\emph{effective nest utilities} given by $\lambda_lI_l$.
\pause \scriptsize{\colAnswer{Because for these assumptions $P_l$ has
    the normal  MNL form}}
\pause \itemAsk Show that  $\lambda_lI_l$ is
at least as high as the utility $\tilde{V}_{lm^*_l}$ 
of the best alternative within the nest and
that $\lambda_lI=\tilde{V}_{lm^*_l}$ for $\lambda_l\to 0$.
\pause \scriptsize{\colAnswer{All contributions of the sum inside the log are
  exponentials and thus positive. \\[-0.7ex]
  Hence, $\lambda_lI_l$ is larger than
  any single $\tilde{V}_{lm}$ including the maximum. For $\lambda_l\to
  0$, only the maximum contributes to the sum}}
\pause \itemAsk Argue that the (potential) selection within a nest is
independent 
from the outer decision and obeys a normal MNL
\pause \scriptsize{\colAnswer{Independent because $P_{lm}=P_l P_{m|l}$, MNL for
  the utilities $\tilde{V}_{lm}/\lambda_l$ for fixed $l$}}
\ei
}


}



\subsubsection{11.2.3 Example: Combined Destination and Mode Choice}

% from ~/vorlesungen/Verkehrsoekonometrie_Ma/discrChoice_cc_Levmar/
% = \pathDiscrChoic

%##############################################################
\frame{\frametitle{11.2.3 Example: Combined Destination and Mode Choice}
%##############################################################
\fig{1.0\textwidth}{figsDiscr/NL-Beispiel_eng.png}

}


%##############################################################
\frame{\frametitle{Combined destination and mode choice: the data}
%##############################################################
{\small
%\begin{center}
\hspace*{-2em}
\begin{tabular}{|c||c|c|c|c|c||c|c|c|c|} \hline
\myBox{2em}{Per-\\son\\group} 
 & \myBox{0.07\textwidth}{T [min]\\Emma,\\ PT}
 & \myBox{0.07\textwidth}{T [min]\\Emma,\\  car}
 & \myBox{0.08\textwidth}{T [min]\\superm,\\ PT}
 & \myBox{0.08\textwidth}{T [min]\\superm,\\  car}
 & \myBox{0.07\textwidth}{Fridge\\fill\\level \\$F$}
 & $y_{11}$ & $y_{12}$ & $y_{21}$ & $y_{22}$ \\ \hline
1  & 25 &  15 & 25 &  20 &  0.9 &  1 &  2 &  0 &  0 \\
2  & 25 &  30 & 40 &  30 &  0.8 &  3 &  0 &  0 &  1 \\
3  & 20 &  20 & 30 &  30 &  0.7 &  2 &  1 &  1 &  1 \\
4  & 25 &  10 & 25 &  10 &  0.6 &  0 &  3 &  0 &  2 \\
5  & 15 &   5 & 30 &  20 &  0.5 &  1 &  2 &  0 &  2 \\
6  & 15 &  15 & 25 &  20 &  0.4 &  1 &  1 &  0 &  1 \\
7  & 15 &  20 & 45 &  45 &  0.3 &  3 &  1 &  0 &  1 \\
8  & 15 &  15 & 15 &  15 &  0.2 &  1 &  0 &  2 &  3 \\
9  & 25 &  15 & 40 &  30 &  0.1 &  1 &  1 &  0 &  1 \\
10 & 25 &  10 & 25 &  20 &  0.0 &  0 &  1 &  1 &  3 \\ \hline
\end{tabular}
%\end{center}
}
}

\providecommand{\tilV}{\tilde{V}}
%##############################################################
\frame{\frametitle{Conditional modal splits}
%##############################################################

\placebox{0.25}{0.65}
{\figSimple{0.44\textwidth}
 {\pathDiscrChoice/NL_Skript_2x2alt_Nest1_fProb.png}}


\visible<3->{\placebox{0.75}{0.65}
{\figSimple{0.44\textwidth}
  {\pathDiscrChoice/NL_Skript_2x2alt_Nest2_fProb.png}}}


\placebox{0.25}{0.20}
{\parbox{0.45\textwidth}{Observed and modelled modal split when driving
    to  ``Aunt Emma''\\[-1em]
\visible<2->{{\small 
\bdma
P_{m|n1} &=& \frac{\exp(\tilV_{n1m}/\lambda_1)}
           {\sum_{m'}\exp(\tilV_{n1m'}/\lambda_1)},\\
\tilV_{n1m}/\lambda_1 &=& \beta_1 T_{n1m}+\beta_2 \delta_{m1},\\
\hatbeta_1 &=&-0.18, \ \hatbeta_2=+0.88
\edma}}
}}

\placebox{0.75}{0.20}{\parbox{0.45\textwidth}
{ 
 \visible<3->{Observed and modelled modal
     split when driving  to the supermarket\\[-1em]}
\visible<4->{{\small 
\bdma
P_{m|n2} &=& \frac{\exp(\tilV_{n2m}/\lambda_2)}
           {\sum_{m'}\exp(\tilV_{n2m'}/\lambda_2)},\\
\tilV_{n2m}/\lambda_2 &=& \beta_3 T_{n2m}+\beta_4 \delta_{m1},\\
\hatbeta_3 &=&-0.29, \ \hatbeta_4=-0.42
\edma}}
}}

}




%##############################################################
\frame{\frametitle{Top-level choice of the type of shop}
%##############################################################

\placebox{0.30}{0.52}
{\figSimple{0.59\textwidth}
  {\pathDiscrChoice/NL_Skript_2x2alt_Toplevel_fProb.png}}

\placebox{0.80}{0.62}
{\parbox{0.36\textwidth}{
Choice of the type of shop: ``Aunt Emma'' vs supermarket:
{\small \bdma
P_{nl} &=& \frac{\exp(W_{nl}+\lambda_l I_{nl})} 
{\sum_{l'}\exp(W_{nl'}+\lambda_l' I_{nl'})}\\[1em]
W_{nl} &=& \beta_5 F_n \delta_{l1} + \beta_6 \delta_{l1}
\edma }
}}

\placebox{0.80}{0.24}
{\parbox{0.4\textwidth}{
{\footnotesize \bdma
I_{n1} &=& \ln\bigg[
  \sum_m \exp\left(\hatbeta_1 T_{n1m}+\hatbeta_2 \delta_{m1}\right)\bigg]\\
I_{n2} &=& \ln\bigg[
  \sum_m \exp\left(\hatbeta_3 T_{n2m}+\hatbeta_4 \delta_{m1}\right)\bigg]\\
\edma}
}}

\placebox{0.50}{0.08}
{\parbox{0.8\textwidth}{
{\small \bdm
\hatbeta_5=2.9, \
\hatbeta_6=-2.0, \
\hat{\lambda}_1=0.17, \
\hat{\lambda}_2=0.21.
\edm}
}}

}

%##############################################################
\frame{\frametitle{Final combined probabilities}
%##############################################################

\placebox{0.35}{0.54}
{\figSimple{0.60\textwidth}
  {\pathDiscrChoice/NL_Skript_2x2alt_NL_fProb.png}}

\pause
\placebox{0.80}{0.55}
{\parbox{0.22\textwidth}{
Combined\\nested choice of shop type and transport mode}}

\placebox{0.50}{0.15}
{\parbox{0.8\textwidth}{
\maindm{
\begin{array}{ll}
P_{ni} &=P_{nl} P_{m|nl}\\
& \text{= Prob(destination)*Prob(mode$|$destination)}
\end{array}
}}}

}


%##############################################################
\frame{\frametitle{Counter check: normal MNL}
%##############################################################

\placebox{0.42}{0.58}
{\figSimple{0.55\textwidth}
  {\pathDiscrChoice/NL_Skript_2x2alt_fProb.png}}


\placebox{0.82}{0.50}
{\parbox{0.36\textwidth}{
\bdm
P_{ni} =\frac{\exp(V_{ni})}{\sum_{i'=1}^4 \exp(V_{ni'})}
\edm
}}

\placebox{0.50}{0.18}
{\parbox{0.8\textwidth}{
{\small $\begin{array}{rcll}
V_1 &=& \beta_1T_1+\beta_2 +\beta_5F+\beta_6 & (l,m)=(1,1) \text{ Emma+PT}\\
V_2 &=& \beta_1T_2+\beta_6 +\beta_5F & (l,m)=(1,2) \text{ Emma+car}\\
V_3 &=& \beta_3T_3+\beta_4 & (l,m)=(2,1) \text{ supermarket+PT}\\
V_4 &=& \beta_3T_4 & (l,m)=(2,2) \text{ supermarket+car}
\end{array}$}
}}

\placebox{0.50}{0.05}{{\small $
\hatbeta_1=-0.15, \
\hatbeta_2=0.60, \
\hatbeta_3=-0.09, \
\hatbeta_4=-0.84, \
\hatbeta_5=3.49, \
\hatbeta_6=-1.76
$}}



}

\subsection{11.3 Advanced I: Mixed-Logit Models}

%##############################################################
\frame{\frametitle{11.3 Advanced I: Mixed-Logit Models }
%##############################################################

if time allows, see German script, Sec. 4.14

}

\subsection{11.4 Advanced II: How to Assess Reliability}

%##############################################################
\frame{\frametitle{11.4  Advanced II: How to Assess Reliability}
%##############################################################

[if time allows, see German script, Sec. 4.15]

}

\end{document}
